{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial\n",
    "In this tutorial you will learn how to use the `TensorFlowConnector` to create a bot that can predict similiar words that are related to a given word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Before continuing, here is a short introduction to the machine learning Python library, TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is TensorFlow?\n",
    "A machine learning library developed by the Google Brain Team. It excels at deep learning and complex, modeling tasks. The structure is graph-based. The nodes in the graph are operations, while the edges are multi-dimensional arrays called tensors.\n",
    "\n",
    "![tf_graph](https://image.slidesharecdn.com/gentlestintrototensorflowpart2-160514044449/95/gentlest-introduction-to-tensorflow-part-2-44-638.jpg?cb=1469416354)\n",
    "\n",
    "All operations are done outside of Python, in a TensorFlow session.\n",
    "\n",
    "Inputs are stored in two, main types of variables, **`placeholder()`**s and **`Variable()`**s. A **`placeholder()`** stores static values, like features and labels in a dateset. A **`Variable()`** stores dynamic values, like weights or biases, which will change during the modeling process as the model is being trained. All inputs are populated during a TensorFlow session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a tensor?\n",
    "In mathematics: A vector stores a one dimension, list of values. A matrix stores values in two dimensions. A tensor stores values in multiple dimensions, sometimes greater than three.\n",
    "\n",
    "![tensors](http://noaxiom.org/img/tensor%20examples.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf_bot\n",
    "We will use the tf_bot example in the examples directory as a guide to create our TensorFlow bot. Let's begin by importing the connectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pybotframework.tf_connector import TensorFlowConnector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BotFramework` class is the main bot framework. This is where all the communication is done with the bot. In our case, the bot is going to connect with the `TensorFlowConnector`, to allow us to use TensorFlow models with the bot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TensorFlowConnector`\n",
    "Let's define our `TensorFlowConnector` object.\n",
    "\n",
    "**Note:** Make sure the TensorFlow model files are in the `examples\\tf_bot\\data` directory in the pybotframework repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_conn = TensorFlowConnector(model_file='model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we pass the already trained, word2vec model (_model.ckpt_) to the connector through the `model` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the Bot\n",
    "After creating our TensorFlow bot, let's interact with it. Let's pass it a list of words and see if it will predict the fourth word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/dave/DataScience/Projects/GitHub/pybotframework/examples/tf_bot/data/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I was unable to find any nearby words.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_conn.respond('Who one the World Series?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/dave/DataScience/Projects/GitHub/pybotframework/examples/tf_bot/data/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I figured it out! The nearest words to fun are saxony connecticut jews.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_conn = TensorFlowConnector(model_file='model.ckpt')\n",
    "tf_conn.respond('Data science is fun!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, one more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/dave/DataScience/Projects/GitHub/pybotframework/examples/tf_bot/data/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I figured it out! The nearest words to afternoon are your geometric unfinished.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_conn = TensorFlowConnector(model_file='model.ckpt')\n",
    "tf_conn.respond('Schedule a meeting with Peter for tomorrow afternoon.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under The Hood\n",
    "So, how does the `TensorFlowConnector` work and allow us to predict similar words using the word2vec model. Let's take a look at this connector in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TensorFlowConnector`\n",
    "Now, we define the **`TensorFlowConnector`** class:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "class TensorFlowConnector(Connector):\n",
    "\n",
    "    def __init__(self, model_file):\n",
    "        Connector.__init__(self)\n",
    "        self.model_path = '/'.join(os.getcwd().split('/')[0:-2])+'/examples/tf_bot/data'\n",
    "        if len(os.getcwd().split('/')) == 1:\n",
    "            self.model_path = '\\''.join(os.getcwd().split('\\'')[0:-2]) + '/examples/tf_bot/data'\n",
    "        self.model = os.path.join(self.model_path, model_file)\n",
    "        self.sess = None\n",
    "        self.graph = tf.Graph()\n",
    "        self.vocab_size = 10000\n",
    "        self.valid_examples = np.arange(self.vocab_size)\n",
    "        self.valid_window = 100\n",
    "        self.batch_size = 128\n",
    "        self.embedding_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TensorFlowConnector` inherits the main, `Connector` class.\n",
    "\n",
    "The class constructor consists of several variables and two parameters. Let's take a look at each:\n",
    "\n",
    "__Parameters__:\n",
    "\n",
    "* `model_file`: The file path to the pre-trained, TensorFlow model.\n",
    "\n",
    "\n",
    "__Constructor Variables__:\n",
    "\n",
    "* `self.model`: The model file including the full path to it's location. \n",
    "\n",
    "* `self.sess`: This will store the TensorFlow sessions variable. It will be defined later on, so it is set to `None` initially.\n",
    "\n",
    "* `self.graph`: Store the TensorFlow graph object here.\n",
    "\n",
    "* `self.vocab_size`: Number of words to used during training.\n",
    "\n",
    "* `self.valid_example`: An empty array of size `self.vocab_size`, used to store the vocabulary.\n",
    "\n",
    "* `self.valid_window`: Window size training.\n",
    "\n",
    "* `self.batch_size`: Batch size used during training.\n",
    "\n",
    "* `self.embedding_size`: Embedding size used during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `_preprocess()`\n",
    "Before passing the input message to the word2vec TensorFlow model, the message needs to be cleaned up and formatted. That is what is done here."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def _preprocess(self, message):\n",
    "    \"\"\"\n",
    "    Clean up the bot message.\n",
    "\n",
    "    :param message: str: Message read from the bot.\n",
    "    :returns: list\n",
    "    \"\"\"\n",
    "    punctuations = \".!?#$%\"\n",
    "    for c in punctuations:\n",
    "        message = message.replace(c, '')\n",
    "    message = message.split(' ')\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_process()`\n",
    "This method passing the cleaned message to the TensorFlow model and creates a prediction."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def _process(self, message, userinfo=None, prediction=None):\n",
    "    \"\"\"\n",
    "    Pass message through the TensorFlow Word2Vec model. Return an analogy prediction; given A is to B as C is to D,\n",
    "    predict D.\n",
    "\n",
    "    :param message: str: Cleaned bot message.\n",
    "    :param userinfo: Parameters pertinent to the user.\n",
    "    :type userinfo: None or list\n",
    "    :param prediction: Prediction output by model.\n",
    "    :type prediction: None or string\n",
    "    :returns: str\n",
    "    \"\"\"\n",
    "\n",
    "    data, count, dictionary, reverse_dictionary = self.collect_data(vocabulary_size=self.vocab_size)\n",
    "\n",
    "    input_word = message[-1]\n",
    "\n",
    "    # Reinitialize things\n",
    "    with self.graph.as_default():\n",
    "\n",
    "        # Input data.\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=[self.batch_size])\n",
    "        train_context = tf.placeholder(tf.int32, shape=[self.batch_size, 1])\n",
    "        valid_dataset = tf.constant(self.valid_examples, dtype=tf.int32)\n",
    "\n",
    "        # Look up embeddings for inputs.\n",
    "        embeddings = tf.Variable(\n",
    "            tf.random_uniform([self.vocab_size, self.embedding_size], -1.0, 1.0))\n",
    "        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "        # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "        normalized_embeddings = embeddings / norm\n",
    "        valid_embeddings = tf.nn.embedding_lookup(\n",
    "            normalized_embeddings, valid_dataset)\n",
    "        similarity = tf.matmul(\n",
    "            valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "        # Add variable initializer.\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session(graph=self.graph) as session:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(session, self.model)\n",
    "\n",
    "        sim = similarity.eval()\n",
    "        if input_word in dictionary:\n",
    "            idx = dictionary[input_word]\n",
    "            valid_word = reverse_dictionary[idx]\n",
    "            top_k = 3  # number of nearest neighbors\n",
    "            nearest = (-sim[idx, :]).argsort()[1:top_k + 1]\n",
    "            log_str = 'nearest words to %s are' % valid_word\n",
    "            for k in range(top_k):\n",
    "                close_word = reverse_dictionary[nearest[k]]\n",
    "                log_str = '%s %s' % (log_str, close_word)\n",
    "            return log_str\n",
    "        else:\n",
    "            return 'no match'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `_postprocess()`\n",
    "Finally, the prediction needs to be formatted to a response the bot might make. We do that in the **`post-process()`** function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def _postprocess(self, prediction):\n",
    "    \"\"\"\n",
    "    Pass the model prediction to a sentence, generating the bot response. Return the response.\n",
    "\n",
    "    :param prediction: str: Tensorflow model prediction.\n",
    "    :return: str\n",
    "    \"\"\"\n",
    "    if prediction != 'no match':\n",
    "        return \"I figured it out! The {}.\".format(prediction)\n",
    "    else:\n",
    "        return \"I'm sorry, I was unable to find any nearby words.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exersize:\n",
    "1. Create a TensorFlow bot.\n",
    "2. Pass three messages to the bot. Does it predict similar words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Advanced Exersize:\n",
    "Using the BotFramework class, combine the TensorFlowConnector with the RegexConnector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
